{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5\n",
    "\n",
    "by Anjali Munasinghe, Jesse McClay, and Andrés Columna\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [MergeSort vs InsertionSort](#Problem-1)\n",
    "\n",
    "2. [HybridSorting](#Problem-2)\n",
    "\n",
    "3. [Binary Search Tree vs Hash Table](#Problem-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "# MergeSort vs InsertionSort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "The CLRS textbook states that insertion sort is more efficient for small n, but that the exact value of n varies between n=7 and n=50 depending on implementation and the environment its run in. This might be counter intuitive at first glance, since InsertionSort is $O(n^2)$ while Mergesort is $O(n \\log{n}) $. But on second glance, it makes sense, as mergesort performs the same number of operations\n",
    "regardless of how partially sorted the array we're sorting is , or how large the array is. Whereas a factor in the time required by insertionsort time is the distance an element is from its final destination. So small arrays imply small distances pushing elements into their final index regardless of where an element originally is. This means the best-case time complexity for insertion sort is $O(n)$ when we're sorting an already sorted array. And $O(nk)$ in general, where k is the most out-of-place element. So if the largest element in an array we're trying to sort in increasing order is in index=n-1, this devolves into $O(n^2)$\n",
    "\n",
    "Despite CLRS' claims, I imagine the $n < 7$ holds for the most efficient implementation of mergesort, which is harder to code (Our version of insertionsort can't be improved in python at least). The easier version of mergesort we're planning on using obviously still has the same asymptotic complexity as any other version of mergesort, but adds some gnarly coefficients on the linear terms that might overwhelm the $n^2$ term for small n. This is due to copying of lists (i.e. mergesort(arr[:mid]) instead of just passing parameters i and mid and mid and j when splitting the left half and right half of the arrays in mergesort.\n",
    "\n",
    "So our guess is that insertionsort will be more efficient than mergesort for $n < 60$. Mergesort will be more efficient for all $n > 60$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version of python used is cPython 3.6.5 |[GCC 4.2.1 Compatible Clang 4.0.1 on darwin VM\n",
    "\n",
    "My computer is a macbook air w/ 8gb RAM.\n",
    "\n",
    "We used the timeit library from the python standard lib to time the functions. We use randint from the random library to create random arrays of variable length.\n",
    "\n",
    "We create ten random arrays for each length n, ranging from array len=1 to len=300. Then we sum how long it takes each algorithm to sort the ten random arrays, and we divide it by ten to find the mean. To be clear, both algorithms sort the same permutation of a random array. The integer sizes used in the random arrays range from 1 to 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InsertionSort implementation source: homemade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertionSort(arr):\n",
    "    for i in range(1, len(arr)):\n",
    "        j = i\n",
    "        val = arr[i]\n",
    "        while j > 0 and arr[j - 1] > val:\n",
    "            arr[j] = arr[j - 1]\n",
    "            j -= 1\n",
    "        arr[j] = val   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InsertionSort test for correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def testInsertionSort():\n",
    "    \n",
    "    from random import randint\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    # test for 100 random arrays of random length between 1 and 100\n",
    "    for _ in range(100):\n",
    "        \n",
    "        arr = [randint(1, 100) for i in range(randint(1,100))]\n",
    "        \n",
    "        copyArr = deepcopy(arr)\n",
    "        insertionSort(arr)\n",
    "        \n",
    "        assert(arr == sorted(arr))\n",
    "        \n",
    "    print(\"Tests Passed\")\n",
    "        \n",
    "testInsertionSort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mergesort implementation, source: Andrés + merge from Python Heapq library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import merge\n",
    " \n",
    "def mergesort(arr):\n",
    "    length = len(arr)\n",
    "    \n",
    "    if length < 2:\n",
    "        return arr\n",
    " \n",
    "    mid = length // 2\n",
    "    lefthalf = mergesort(arr[:mid])\n",
    "    righthalf = mergesort(arr[mid:])\n",
    " \n",
    "    return list(merge(lefthalf, righthalf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test mergesort for correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mergesort Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def testMergesort():\n",
    "    \n",
    "    from random import randint\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    # test for 100 random arrays of random length between 1 and 100\n",
    "    for _ in range(100):\n",
    "        \n",
    "        arr = [randint(1, 100) for i in range(randint(1,100))]\n",
    "        \n",
    "        copyArr = deepcopy(arr)\n",
    "        \n",
    "        assert(mergesort(arr) == sorted(arr))\n",
    "        \n",
    "    print(\"Mergesort Tests Passed\")\n",
    "        \n",
    "testMergesort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time mergesort vs insertion sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "\n",
    "mergesortTimesArr = [] \n",
    "insertTimesArr = []\n",
    "\n",
    "# time sorts from len(arr) == 1 to len(arr) == 100 \n",
    "for arrlen in range(1, 200):\n",
    "    \n",
    "    mergeTimes  = 0\n",
    "    insertTimes = 0\n",
    "    \n",
    " \n",
    "    # takes average of ten runs\n",
    "    for _ in range(30):\n",
    "        arr1 = [randint(1, 1000) for i in range(arrlen)]\n",
    "        arr2 = deepcopy(arr1)\n",
    "        \n",
    "        mergeTimes  += timeit('mergesort(arr1)',     number=1, globals=globals())\n",
    "        insertTimes += timeit('insertionSort(arr2)', number=1, globals=globals())\n",
    "        \n",
    "    meanMergeTime =     mergeTimes  / 30.\n",
    "    meanInsertionTime = insertTimes / 30.\n",
    "    \n",
    "    mergesortTimesArr.append(meanMergeTime)\n",
    "    insertTimesArr.append(meanInsertionTime)\n",
    "    \n",
    "print(mergesortTimesArr, file=open(\"mergeData.txt\", \"a\"))\n",
    "print(insertTimesArr, file=open(\"insertData.txt\", \"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for graphing in Mathematica 11\n",
    "\n",
    "```mathematica\n",
    "MergesortTimeData = \n",
    "  ToExpression@\n",
    "   StringReplace[\n",
    "    Import[\"/Users/andres/Desktop/EECS431/HW4/mergeData.txt\"], {\"e\" \"*^\", \"[\" -> \"{\", \"]\" -> \"}\"}];\n",
    "InsertionTimeData = \n",
    "  ToExpression@\n",
    "   StringReplace[\n",
    "    Import[\"/Users/andres/Desktop/EECS431/HW4/insertData.txt\"], {\"e\" \\\"*^\", \"[\" -> \"{\", \"]\" -> \"}\"}];\n",
    "ListLinePlot[{InsertionTimeData, MergesortTimeData}, \n",
    " PlotLegends -> {\"InsertionSort\", \"MergeSort\"}, \n",
    " AxesLabel -> {HoldForm[\"Len(x)\"], HoldForm[\"Seconds\"]}, \n",
    " PlotLabel -> HoldForm[\"InsertionSort vs MergeSort\"], \n",
    " LabelStyle -> {14, GrayLevel[0]}]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "the graph below indicates that mergesort becomes as fast as insertionsort around $n=95$ and clearly overtakes it at around $ n=130 $\n",
    "\n",
    "For $n < 90$, insertionsort is consistently faster than mergesort by tens of microseconds.  For $n > 150$, the $n^2$ time complexity of insertion sort becomes apparent. And the $n \\log{n}$ time complexity of mergsort is noticeably faster.\n",
    "\n",
    "In our graph, The x-axis denotes the length of the array of integers (i.e. n). The y-axis denots the time it takes to sort the array in seconds.\n",
    "The data is discrete, so it should really be a scatter plot but lines were drawn in between points so as to make it easier to read when lines cross. We used Wolfram Mathematica to graph the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://cdn.pbrd.co/images/HKrGrqb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions + Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a second, clearer run of timing for n < 200.\n",
    "\n",
    "![second run](https://cdn.pbrd.co/images/HKzrUct.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon closer inspection, the precise value at which MergeSort overtakes InsertionSort is n=103. The values are in seconds. n equals the number of elements in the array\n",
    "\n",
    "![](https://cdn.pbrd.co/images/HKA3raz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an in-place version of Mergesort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mergesort2 Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# using a different version in-place version of mergesort\n",
    "\n",
    "# merge sort\n",
    "def mergeSort2(arr, first, last):\n",
    "    if first < last:\n",
    "            middle = (first+last)//2            \n",
    "            mergeSort2(arr, first, middle)\n",
    "            mergeSort2(arr, middle+1, last)\n",
    "            merge2(arr, first, middle, last)\n",
    "\n",
    "def merge2(arr, first, middle, last):\n",
    "    left = arr[first: middle + 1]\n",
    "    right = arr[middle+1:last+1]\n",
    "    \n",
    "    left.append(sys.maxsize)\n",
    "    right.append(sys.maxsize)\n",
    "    \n",
    "    i = j = 0\n",
    "\n",
    "    for k in range (first, last+1):\n",
    "        if left[i] <= right[j]:\n",
    "            arr[k] = left[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            arr[k] = right[j]\n",
    "            j += 1\n",
    "            \n",
    "def testMergeSort2():\n",
    "    \n",
    "    from random import randint\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    # test for 100 random arrays of random length between 1 and 100\n",
    "    for _ in range(100):\n",
    "        \n",
    "        arr = [randint(1, 100) for i in range(randint(1,100))]\n",
    "        \n",
    "        copyArr = deepcopy(arr)\n",
    "        mergeSort2(arr, 0, len(arr)-1)\n",
    "        \n",
    "        assert(arr == sorted(arr))\n",
    "        \n",
    "    print(\"Mergesort2 Tests Passed\")\n",
    "        \n",
    "testMergeSort2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "\n",
    "mergesortTimesArr = [] \n",
    "insertTimesArr = []\n",
    "\n",
    "# time sorts from len(arr) == 1 to len(arr) == 100 \n",
    "for arrlen in range(1, 100):\n",
    "    \n",
    "    mergeTimes  = 0\n",
    "    insertTimes = 0\n",
    "    \n",
    " \n",
    "    # takes average of ten runs\n",
    "    for _ in range(30):\n",
    "        arr1 = [randint(1, 1000) for i in range(arrlen)]\n",
    "        arr2 = deepcopy(arr1)\n",
    "        \n",
    "        mergeTimes  += timeit('mergeSort2(arr1,0,len(arr1)-1)',     number=1, globals=globals())\n",
    "        insertTimes += timeit('insertionSort(arr2)', number=1, globals=globals())\n",
    "        \n",
    "    meanMergeTime =     mergeTimes  / 30.\n",
    "    meanInsertionTime = insertTimes / 30.\n",
    "    \n",
    "    mergesortTimesArr.append(meanMergeTime)\n",
    "    insertTimesArr.append(meanInsertionTime)\n",
    "    \n",
    "print(mergesortTimesArr, file=open(\"mergeData.txt\", \"a\"))\n",
    "print(insertTimesArr, file=open(\"insertData.txt\", \"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mahlink](https://preview.ibb.co/bzrO7f/image.png)\n",
    "\n",
    "For the in-place mergesort, mergesort surpasses insertionSort at n=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Under the conditions tested, our implementation of insertion sort produces a faster algorithm for n < 95, while mergesort is faster for n > 130. For n between 95 and 130 the two sorting algorithms are indistinguishable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Problem 2\n",
    "## Hybrid Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: Briefly describe what results you believe you will find. It is important to write your hypothesis\n",
    "before you start conducting experiments as a way of acknowledging your initial expectations. Note: you\n",
    "will not lose points for your hypothesis being incorrect; in fact getting a result different from your\n",
    "hypothesis will often be more exciting and more of a learning experience.\n",
    "\n",
    "\n",
    "Methods: Describe step-by-step the experiments that you conduct. Provide the source code that you use,\n",
    "and details about which compiler you use, how you compile it (e.g., optimization flags), and the range of\n",
    "inputs that you feed into your program. Your methods should accurately reflect how you actually generated\n",
    "your data such that, someone reading them can replicate your experiment.\n",
    "Results: Present the data that your experiments produced. In most cases this will be a graph (as described\n",
    "in each question below) and a brief explanation to make sure the reader understands the data in that graph.\n",
    "\n",
    "\n",
    "Discussion: Provide a brief discussion of your data. Did anything about it surprise you? Were there any\n",
    "unexpected challenges in collecting the data? This section is where you will answer specific questions\n",
    "posed in the problems below.\n",
    "\n",
    "\n",
    "Conclusions: Present a concise take-away for this experiment. For example, “Under the conditions tested,\n",
    "data structure A produces a faster algorithm for n < 1000, while data structure B is faster for n > 1500. For\n",
    "n between 1000 and 1500 the two data structures are indistinguishable.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "Given that our last experiment yielded that Mergesort surpasses InsertionSort's performance at `len(arr)=100`, I'll stick with that. I hypothesize that using insertionSort for all subarrays n < 100, and mergesort for all n >= 100 will yield the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "### InsertionSort and MergeSort from problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import merge\n",
    " \n",
    "def mergeSort(arr):\n",
    "    length = len(arr)\n",
    "    \n",
    "    if length < 2:\n",
    "        return arr\n",
    " \n",
    "    mid = length // 2\n",
    "    lefthalf = mergesort(arr[:mid])\n",
    "    righthalf = mergesort(arr[mid:])\n",
    " \n",
    "    return list(merge(lefthalf, righthalf))\n",
    "\n",
    "def insertionSort(arr):\n",
    "    for i in range(1, len(arr)):\n",
    "        j = i\n",
    "        val = arr[i]\n",
    "        while j > 0 and arr[j - 1] > val:\n",
    "            arr[j] = arr[j - 1]\n",
    "            j -= 1\n",
    "        arr[j] = val  \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import merge\n",
    " \n",
    "def hybridSort(arr, k=103):\n",
    "    length = len(arr)\n",
    "    \n",
    "    if length < k:\n",
    "        return insertionSort(arr)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        mid = length // 2\n",
    "        lefthalf = hybridSort(arr[:mid])\n",
    "        righthalf = hybridSort(arr[mid:])\n",
    "        return list(merge(lefthalf, righthalf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.34 ms ± 1.03 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r10 arr = deepcopy(original)\n",
    "\n",
    "hybridSort(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8 ms ± 1.52 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r10 arr = deepcopy(original)\n",
    "\n",
    "mergeSort(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing the sorts\n",
    "\n",
    "I added a parameter k to the hybridsort function that determines the cutoff when insertionSort takes over in the mergesort routine. So that for all subarrays were sorting that are less than `len(k)`, insertion sort will be used. I tested k=20,40,60,...,140. (intervals of 20).\n",
    "\n",
    "After determining with a precision of +/- 20 what the best cutoff was, I varied the k parameter at intervals of 10, in multiple iterations of trial and error.\n",
    "\n",
    "The way I timed the different versions of HybridSort is for every array length, 30 (probably) different random integer arrays of `len(n)` are created. A deep copy of the same array is made for each algorithm to sort, since some algorithms sort in-place and we wanna avoid feeding an already sorted array to an algorithm to sort and give us a false impression of how fast it is. `Timeit` times how long it takes to sort those 30 algorithms, each only sorted once as to avoid cache optimizations that again, obfuscate actual performance. Then the average time is taken for an individual array length. We ultimately have an array of times, where the index of an element signifys an array length, and the value at the index denotes the average time it took the algorithm to sort those 30 random arrays.  \n",
    "\n",
    "I used the Timeit module from python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "\n",
    "arr20 = []\n",
    "arr40 = []\n",
    "arr60 = []\n",
    "arr80 = []\n",
    "arr100 = []\n",
    "arr120 = []\n",
    "arr140 = []\n",
    "a160 = []\n",
    "\n",
    "# time sorts from len(arr) == 1 to len(arr) == 100 \n",
    "for arrlen in range(0, 60):\n",
    "    t = 100\n",
    "    t20 = 0\n",
    "    t40 = 0\n",
    "    t60 = 0\n",
    "    t80 = 0\n",
    "    t100 = 0\n",
    "    t120 = 0\n",
    "    t140 = 0\n",
    "    \n",
    "    runs = 1\n",
    "    \n",
    "    for _ in range(t):\n",
    "    \n",
    "        a20 = [randint(1, 1000) for i in range(arrlen)]\n",
    "        a40 = deepcopy(a20)\n",
    "        a60 = deepcopy(a20)\n",
    "        a80 = deepcopy(a20)\n",
    "        a100 = deepcopy(a20)\n",
    "        a120 = deepcopy(a20)\n",
    "        a140 = deepcopy(a20)\n",
    "        a160 = deepcopy(a20)\n",
    "\n",
    "\n",
    "        t100 += timeit('hybridSort(a100, 25)', number=runs, globals=globals())\n",
    "        t120 += timeit('hybridSort(a120, 30)', number=runs, globals=globals())\n",
    "        t140 += timeit('hybridSort(a140, 35)', number=runs, globals=globals())\n",
    "    \n",
    "    \n",
    "    arr20.append(t20/t)\n",
    "    arr40.append(t40/t)\n",
    "    arr60.append(t60/t)\n",
    "    arr80.append(t80/t)\n",
    "    arr100.append(t100/t)\n",
    "    arr120.append(t120/t)\n",
    "    arr140.append(t140/t)\n",
    "\n",
    "\n",
    "print(arr20, file=open(\"t20.txt\", \"a\"))\n",
    "print(arr40, file=open(\"t40.txt\", \"a\"))\n",
    "print(arr60, file=open(\"t60.txt\", \"a\"))\n",
    "print(arr80, file=open(\"t80.txt\", \"a\"))\n",
    "print(arr100, file=open(\"t100.txt\", \"a\"))\n",
    "print(arr120, file=open(\"t120.txt\", \"a\"))\n",
    "print(arr140, file=open(\"t140.txt\", \"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-11-03%20at%208.28.22%20PM.png](https://images2.imgbox.com/4c/e2/gTC5HRgV_o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph denotes running hybridSorts with cutoffs of 20,40,...,140 on arrays of size range 0 to 200.\n",
    "\n",
    "Noticeable in this graph is that HybridSort(k=140) improves drastically around `len(n)=140`, meaning that we're switching too late. This drop trend happens all the way to `Hybrid(k=60)`, so we infer from this graph that the optimal switch spot k must be < 60. So we should increase the resolution/decrease the interval size around k < 60."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-11-03%20at%209.40.03%20PM.png](https://images2.imgbox.com/b3/b7/tcLoGcFz_o.png)\n",
    "\n",
    "The graph plots running times of hybridSorts with cutoffs of 20,40, and 60 on arrays of size `0 < len(n) < 60`.\n",
    "\n",
    "Notice how k=10 clearly switches to mergesort too early, and k=50 too late. So our answer must be around between 10 and 50. i.e. around 30. This contradicts the hypothesis. Really strange!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-11-03%20at%2010.28.47%20PM.png](https://images2.imgbox.com/0d/8a/Uci4QSml_o.png)\n",
    "\n",
    "Here, the three k-values produce indistinguishable results, more or less. So I'll stop doing more trials and decide k=30 is roughly ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "\n",
    "mergesortTimesArr = [] \n",
    "insertTimesArr = []\n",
    "hybridTimesArr = []\n",
    "sortedTimesArr = []\n",
    "\n",
    "# time sorts from len(arr) == 1 to len(arr) == 100 \n",
    "for arrlen in range(1, 250):\n",
    "    \n",
    "    mergeTimes  = 0\n",
    "    insertTimes = 0\n",
    "    hybridTimes = 0\n",
    "    sortedTimes = 0\n",
    "    n = 15\n",
    " \n",
    "    # takes average of ten runs\n",
    "    for _ in range(n):\n",
    "        arr1 = [randint(1, 1000) for i in range(arrlen)]\n",
    "        arr2 = deepcopy(arr1)\n",
    "        arr3 = deepcopy(arr1)\n",
    "        arr4 = deepcopy(arr1)\n",
    "        \n",
    "        mergeTimes  += timeit('mergesort(arr1)',     number=1, globals=globals())\n",
    "        insertTimes += timeit('insertionSort(arr2)', number=1, globals=globals())\n",
    "        hybridTimes += timeit('hybridSort(arr3, 30)', number=1, globals=globals())\n",
    "        sortedTimes += timeit('sorted(arr4)', number=1, globals=globals())\n",
    "        \n",
    "    meanMergeTime =     mergeTimes  / n\n",
    "    meanInsertionTime = insertTimes / n\n",
    "    meanHybridTime = hybridTimes / n\n",
    "    meanSortedTime = sortedTimes / n\n",
    "    \n",
    "    mergesortTimesArr.append(meanMergeTime)\n",
    "    insertTimesArr.append(meanInsertionTime)\n",
    "    hybridTimesArr.append(meanHybridTime)\n",
    "    sortedTimesArr.append(meanSortedTime)\n",
    "    \n",
    "    \n",
    "print(mergesortTimesArr, file=open(\"mergeData.txt\", \"a\"))\n",
    "print(insertTimesArr, file=open(\"insertData.txt\", \"a\"))\n",
    "print(hybridTimesArr, file=open(\"hybridData.txt\", \"a\"))\n",
    "print(sortedTimesArr, file=open(\"sortedData.txt\", \"a\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-11-03%20at%2010.16.12%20PM.png](https://images2.imgbox.com/b8/1d/ITUmqZyT_o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This graphs HybridSort(k=30) vs InsertionSort vs. MergeSort. HybridSort is clearly superior at all instances. It follows the slope of insertion sort for n < 30, and then follows the slope of MergeSort albeit merging at one point, and then matches it with a positive offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Surprisingly, the optimal switch spot is k=30. This contradicts our results from problem 1 and thus contradicts our hypothesis that k=100 would be the best switch length based on problem 1 data.\n",
    "\n",
    "Since this is an empirical result, I have no confident way to reconcile theory with it. Maybe something is happening at the level of the compiler that could explain this? Because Python is an interpreted language, and I can't/won't read byte code, I'll never know why this is.\n",
    "\n",
    "My attempt at an explanation: Maybe InsertionSort + MergeSort is greater than the sum of its parts- As in, maybe insertionSort is so efficient at sorting partially sorted small arrays, and mergeSort so effective dividing lists in half to get them to the small array cutoff where insertionSort is efficient, that together is better than either one by themselves would suggest.  Mergesort(n==100) is mergesort, recursively, all the way down the tree. But in HybridSort(k==25,n=100), for example, it's really calling mergesort for n=100 then twice for n=50, then four times for n=25, and then it takes advantage of insertionsort. Since halving by two so quickly gets us to the base case where insertion sort can be efficient, simply seeing were just mergesort and insertionsort lineplots meet is misleading. So maybe mergesort is so wasteful while merging small subpartitions of nearly sorted arrays that it makes the overall run time of just mergesort(at n=100) deceptively long.\n",
    "\n",
    "A challenge in collecting data is that plotting all k values simultaneaously was too much clutter on a graph, so a time-consuming process of trial was used.\n",
    "\n",
    "Also, the timing at each array length was a function of how many inversions the random array produced needed. So every once in a while, random spikes would show up in the graph the muddied the water, so to speak. In order to deal with this, I had to increase the number of trial runs at each n up to 50 sometimes. But this was too computationally expensive. So reading the optimal k value required a lot of zooming into graphs.\n",
    "\n",
    "Since I know that python's built-in sorted functin uses Timsort, which is a hybrid sorting algorithm itself (albeit Quicksort + InsertionSort) I compared it to our Hybrid Algorithm just for kicks.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-11-03%20at%2011.01.46%20PM.png](https://images2.imgbox.com/e5/b3/jc4UUerJ_o.png)\n",
    "\n",
    "Evidently, even our hybrid algorithm sucks compared to built-in `Sorted` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Under the conditions tested, the optimal switch length for a hybrid merge-insertion sort is, roughly 30. This contradicts our problem 1 data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "## Binary Search Trees vs Hash Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "The Time-Complexity of inserting in a balanced binary search tree is $\\log{n}$, while inserting into a hashTable is $O(1)$. This is what is listed in the CPP reference pages for Multiset and Unsorted Multiset. However, I imagine a hash table has to double as it grows, so they might really mean a hash-set is an amortized $O(1)? Also, depending on how good the built-in hash function for unsorted_multiset is at preventing collisions, maybe performance will linear in the worst case. But I trust the coders of the STL to obviously not do that. \n",
    "\n",
    "So I'll say the hash function will make the inserting into a bst faster up until 100 insertions, and then the BST will be faster for all values greater than 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods: Describe step-by-step the experiments that you conduct. \n",
    "\n",
    "Provide the source code that you use,\n",
    "and details about which compiler you use, how you compile it (e.g., optimization flags), and the range of\n",
    "inputs that you feed into your program. \n",
    "\n",
    "Your methods should accurately reflect how you actually generated\n",
    "your data such that, someone reading them can replicate your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "I tested multiset::insert vs unsorted_multiset::insert for inserting 2 integers, 4, 8, ..., $2^{23}$\n",
    "\n",
    "Those are C++ implementation of Binary Search Trees and Hash-Set respectively.\n",
    "\n",
    "The compilation flags used were : `g++ -std=c++11 -o3 main.cpp -o a.out`\n",
    "\n",
    "I used the `<chrono>` library to time the insertions.\n",
    "\n",
    "The times were exported to a text file. The text file was then imported into mathematica to create the graphs and tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "//\n",
    "//  main.cpp\n",
    "//  CSE 431, Anjali, Jesse, Andres\n",
    "//\n",
    "//\n",
    "\n",
    "#include <iostream>\n",
    "#include <set>\n",
    "#include <unordered_set>\n",
    "#include <fstream>\n",
    "#include <iomanip>\n",
    "#include <chrono>\n",
    "#include <math.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main(int argc, const char * argv[]) {\n",
    "    \n",
    "    \n",
    "    std::unordered_multiset<int> uset;\n",
    "    std::multiset<int> set;\n",
    "\n",
    "    ofstream setFile(\"set.txt\");\n",
    "    ofstream usetFile(\"uset.txt\");\n",
    "    \n",
    "    // set precision\n",
    "    setFile << fixed << showpoint;\n",
    "    setFile << setprecision(8);\n",
    "    cout << fixed << showpoint;\n",
    "    cout << setprecision(8);\n",
    "    usetFile << fixed << showpoint;\n",
    "    usetFile << setprecision(8);\n",
    "    \n",
    "    //myfile << \"Writing this to a file.\\n\";\n",
    "    auto start = chrono::steady_clock::now();\n",
    "    auto end = chrono::steady_clock::now();\n",
    "    \n",
    "    double elapsedTime = double(chrono::duration_cast<chrono::nanoseconds>(end-start).count());\n",
    "    \n",
    "    long long i = 1;\n",
    "    int x = 0;\n",
    "    \n",
    "    int exponent = 20;\n",
    "\n",
    "    // Iterate from 1 up to exponent\n",
    "    while (i <= exponent){\n",
    "        \n",
    "        set.clear();\n",
    "        uset.clear();\n",
    "        \n",
    "        double setRunTime = 0;\n",
    "        double usetRunTime = 0;\n",
    "        \n",
    "        // loop 2^i times\n",
    "        for(long long j = 0; j < pow(2, i); j++){\n",
    "            \n",
    "            x = rand();\n",
    "            \n",
    "            start = chrono::steady_clock::now();\n",
    "            set.insert(x);\n",
    "            end = chrono::steady_clock::now();\n",
    "            setRunTime += double(chrono::duration_cast<chrono::nanoseconds>(end-start).count());\n",
    "            \n",
    "            start = chrono::steady_clock::now();\n",
    "            uset.insert(x);\n",
    "            end = chrono::steady_clock::now();\n",
    "            usetRunTime += double(chrono::duration_cast<chrono::nanoseconds>(end-start).count());\n",
    "        }\n",
    "        \n",
    "        setFile << setRunTime << \"\\n\";\n",
    "        usetFile << usetRunTime << \"\\n\";\n",
    "        \n",
    "        i += 1;\n",
    "    }\n",
    "    \n",
    "    \n",
    "    setFile.close();\n",
    "    usetFile.close();\n",
    "    \n",
    "    cout << \"Success!\\n\";\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Plotting\n",
    "\n",
    "```Mathematica\n",
    "setData = \n",
    "  ToExpression@\n",
    "   StringSplit@Import[\"/Users/andres/Desktop/EECS431/set.txt\"];\n",
    "usetData = \n",
    "  ToExpression@\n",
    "   StringSplit@Import[\"/Users/andres/Desktop/EECS431/uset.txt\"];\n",
    "ListLogLogPlot[{setData, usetData}, \n",
    " PlotLegends -> {\"Tree\", \"Hash Table\"}, \n",
    " AxesLabel -> {HoldForm[\"Number of inseertions\"], \n",
    "   HoldForm[\"nanoseconds\"]}, \n",
    " PlotLabel -> HoldForm[\"Hash Table insertions vs Tree Insertions\"], \n",
    " LabelStyle -> {14, GrayLevel[0]}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "BST was the faster at insertion for $\\leq 2^5$ insertions. Hash Table was faster for $\\gt 2^5$ insertions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-11-04%20at%203.17.58%20PM.png](https://images2.imgbox.com/c7/29/0NMQhUJu_o.png)\n",
    "\n",
    "Log Log Plot of Performance Comparison of `multiset::insert` vs `unorderered_multiset::insert`, that is, inserting into a tree vs inserting into a hash table. Note that $10^{10}$ nanoseconds = 10 seconds, so we reached the three second threshold requirement listed in the HW4 spec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-11-04%20at%205.06.57%20PM.png](https://images2.imgbox.com/21/bb/Np2pIhte_o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "What's interesting is that even for $2^{23}$ insertions, the hash table was just 2.5 times faster, and not around 23 times faster that the raw big O comparison would suggest.\n",
    "\n",
    "Another problem was that I wasn't getting any differences in performance between the two because I was unknowingly testing for too few n. Only when I cranked it up to around 2^{20} did the performance advantage of hash tables become noticeable. That's part of the reason why i used the chronos library. I was thinking the timing library provided in the homework specs wasn't precise enough to detect a difference? lol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "A cpp binary search tree is more efficient at $2^5$ insertions and less. A cpp Hash Table is more efficient at 2^12 insertions and greater. Between $2^6$ and $2^11$, the algorithms perform roughly equally well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
